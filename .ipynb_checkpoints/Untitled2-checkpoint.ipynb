{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('data/poem.tang.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'雷声震，连日不收声。此象正为多失信，为他官吏不能清，天令与人闻。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(list(map(len, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(list(map(len, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.836638629523883"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(len, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(list(map(len, data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    \"\"\"RNNLM模型配置项\"\"\"\n",
    "    embedding_dim = 5  # 词向量维度\n",
    "\n",
    "    rnn_type = 'LSTM'  # 支持RNN/LSTM/GRU\n",
    "    hidden_dim = 5  # 隐藏层维度\n",
    "    num_layers = 2  # RNN 层数\n",
    "\n",
    "    dropout = 0.5  # 丢弃概率\n",
    "    tie_weights = True  # 是否绑定参数\n",
    "\n",
    "    clip = 0.25  # 用于梯度规范化\n",
    "    learning_rate = 0.5  # 初始学习率\n",
    "\n",
    "    num_epochs = 50  # 迭代轮次\n",
    "    log_interval = 50  # 每隔多少个批次输出一次状态\n",
    "    save_interval = 3  # 每个多少个轮次保存一次参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNNLM(nn.Module):\n",
    "    \"\"\"基于RNN的语言模型，包含一个encoder，一个rnn模块，一个decoder。\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(RNNLM, self).__init__()\n",
    "\n",
    "        v_size = config.vocab_size\n",
    "        em_dim = config.embedding_dim\n",
    "        dropout = config.dropout\n",
    "        \n",
    "        self.rnn_type = rnn_type = config.rnn_type\n",
    "        self.hi_dim = hi_dim = config.hidden_dim\n",
    "        self.n_layers = n_layers = config.num_layers\n",
    "\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(v_size, em_dim)\n",
    "\n",
    "        # rnn: RNN / LSTM / GRU\n",
    "        self.rnn = getattr(nn, rnn_type)(em_dim, hi_dim, n_layers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(hi_dim, v_size)\n",
    "\n",
    "        # tie_weights将encoder和decoder的参数绑定为同一参数。\n",
    "        if config.tie_weights:\n",
    "            if hi_dim != em_dim:  # 这两个维度必须相同\n",
    "                raise ValueError('When using the tied flag, hi_dim must be equal to em_dim')\n",
    "            self.decoder.weight = self.encoder.weight\n",
    "\n",
    "        self.init_weights()  # 初始化权重\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        seq_len = len(inputs)\n",
    "        emb = self.drop(self.encoder(inputs).view(seq_len, 1, -1))\n",
    "        output, hidden = self.rnn(emb, hidden)\n",
    "        output = self.decoder(output.view(seq_len, -1))\n",
    "        return output, hidden  # 复原\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"权重初始化，如果tie_weights，则encoder和decoder权重是相同的\"\"\"\n",
    "        init_range = 0.1\n",
    "        self.encoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "\n",
    "    def init_hidden(self):\n",
    "        \"\"\"初始化隐藏层\"\"\"\n",
    "        weight = next(self.parameters()).data\n",
    "        if self.rnn_type == 'LSTM':  # lstm：(h0, c0)\n",
    "            return (Variable(weight.new(self.n_layers, 1, self.hi_dim).zero_()),\n",
    "                    Variable(weight.new(self.n_layers, 1, self.hi_dim).zero_()))\n",
    "        else:  # gru 和 rnn：h0\n",
    "            return Variable(weight.new(self.n_layers, 1, self.hi_dim).zero_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.vocab_size = 5000\n",
    "model = RNNLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Variable(torch.LongTensor([1, 2, 3, 4, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.2711e-03  1.2456e-02  2.5378e-03  ...  -1.5393e-02 -1.9186e-02  2.1262e-02\n",
       " 4.4557e-03  1.6255e-02  1.5406e-03  ...  -2.0911e-02 -2.6532e-02  2.9455e-02\n",
       " 4.9983e-03  2.0719e-02  2.6081e-03  ...  -2.2978e-02 -2.8996e-02  3.6590e-02\n",
       " 3.4249e-03  2.0958e-02  9.1040e-04  ...  -2.2375e-02 -2.7427e-02  3.8423e-02\n",
       " 2.9938e-03  2.2964e-02  4.2221e-04  ...  -2.3548e-02 -2.9987e-02  4.2601e-02\n",
       "[torch.FloatTensor of size 5x5000]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = model(inputs, model.init_hidden())\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_file(filename, mode='r'):\n",
    "    return open(filename, mode=mode, encoding='utf-8', errors='ignore')\n",
    "\n",
    "class Corpus(object):\n",
    "    \"\"\"\n",
    "    文本预处理，获取词汇表，并将字符串文本转换为数字序列。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_dir, vocab_dir):\n",
    "        assert os.path.exists(train_dir), 'File %s does not exist.' % train_dir\n",
    "        \n",
    "        if not os.path.exists(vocab_dir):\n",
    "            words = list(set(list(open_file(train_dir).read().replace('\\n', ''))))\n",
    "            open_file(vocab_dir, 'w').write('\\n'.join(sorted(words)) + '\\n')\n",
    "        \n",
    "        words = open_file(vocab_dir).read().strip().split('\\n')\n",
    "        word_to_id = dict(zip(words, range(len(words))))\n",
    "        \n",
    "        data = []\n",
    "        with open_file(train_dir) as f:\n",
    "            for line in f:\n",
    "                poem = [word_to_id[x] for x in line.strip() if x in word_to_id]\n",
    "                data.append(poem)\n",
    "        \n",
    "        self.words = words\n",
    "        self.word_to_id = word_to_id\n",
    "        self.data = data\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Corpus length: %d, Vocabulary size: %d\" % (len(self.data), len(self.words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus('data/poem.tang.txt', 'data/poem.vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Corpus length: 51836, Vocabulary size: 7353"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Corpus length: 51836, Vocabulary size: 7353"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config()\n",
    "corpus = Corpus('data/poem.tang.txt', 'data/poem.vocab.txt')\n",
    "config.vocab_size = len(corpus.words)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = RNNLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 5545\n",
       "[torch.LongTensor of size 1x1]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Variable(torch.rand(1, 1).mul(len(corpus.words)).long(), volatile=True) \n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7351"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output, hidden = model(inputs, hidden)\n",
    "word_weights = output.squeeze().data.div(1).exp().cpu()\n",
    "word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(model, words, word_len=50, temperature=1.0):\n",
    "    \"\"\"生成一定数量的文本，temperature结合多项式分布可增添抽样的多样性。\"\"\"\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden()  # batch_size为1\n",
    "    inputs = Variable(torch.rand(1, 1).mul(len(words)).long(), volatile=True)  # 随机选取一个字作为开始\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(word_len):  # 逐字生成\n",
    "        output, hidden = model(inputs, hidden)\n",
    "        word_weights = output.squeeze().data.div(temperature).exp().cpu()\n",
    "\n",
    "        # 基于词的权重，对其再进行一次抽样，增添其多样性，如果不使用此法，会导致常用字的无限循环\n",
    "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "        inputs.data.fill_(word_idx)  # 将新生成的字赋给inputs\n",
    "        word = words[word_idx]\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate2(model, words, word_len=50, temperature=1.0):\n",
    "    \"\"\"生成一定数量的文本，temperature结合多项式分布可增添抽样的多样性。\"\"\"\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden()  # batch_size为1\n",
    "    inputs = Variable(torch.rand(1, 1).mul(len(words)).long(), volatile=True)  # 随机选取一个字作为开始\n",
    "    if use_cuda:\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    word_list = []\n",
    "    for i in range(word_len):  # 逐字生成\n",
    "        output, hidden = model(inputs, hidden)\n",
    "        topv, topi = output.data.topk(1)\n",
    "        word_idx = topi[0][0]\n",
    "        inputs.data.fill_(word_idx)  # 将新生成的字赋给inputs\n",
    "        word = words[word_idx]\n",
    "        word_list.append(word)\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['不',\n",
       " '不',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，',\n",
       " '，',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '。',\n",
       " '山',\n",
       " '不',\n",
       " '不',\n",
       " '不',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，',\n",
       " '，',\n",
       " '人',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '不',\n",
       " '人',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '人',\n",
       " '，']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate2(model, corpus.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.430486450195312\n",
      "6.18111572265625\n",
      "不不，人不不，，，人不，人人不，，，人不，不人不，，，人不不。人不不不，不人不，，，人不不。山不不不\n",
      "6.320678100585938\n",
      "6.332272338867187\n",
      "不有，人有有，，人，人人有，人人有，人人有，人人有，人人有，人人人，人人有，人人人，人人有，人人人，\n",
      "6.2412548828125\n",
      "6.224560546875\n",
      "不不，人人人，，人，人人人，人人人，人人人，人人人，人人人，人人人，人人人，人人人，人人人，人人人，\n",
      "6.3541192626953125\n",
      "6.227049560546875\n",
      "不不，人人人，，人，人人人，，，不不人，人人人人，人不人人，人人人人，人人人人，人人人人，人人人人，\n",
      "6.189553833007812\n",
      "6.263450927734375\n",
      "不人，人人人，，，人不人。人不不人，，，人不人，人人人，，，人不人。，人。人人人，，，人不人。，人。\n",
      "6.363748168945312\n",
      "6.36052490234375\n",
      "不不，人人人，，，人不人，，，人不人人。，不不。，，人不人，，，人不不人。，不不。，，人不人，，，人\n",
      "6.250488891601562\n",
      "6.346702880859375\n",
      "不不，人人人，，人人。，不人。，人。人人人，，人人。，不人。，人，人不人人，人人人人，人人人人，人人\n",
      "6.21375732421875\n",
      "6.197671508789062\n",
      "不不，不不不不，不不不不，不不不不，，人，不不不不，，，不不不不。，不不。，，不不不不。，不不。，人\n",
      "6.261364135742188\n",
      "6.24614990234375\n",
      "不不，不不不，，，不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不\n",
      "6.3384228515625\n",
      "6.324801025390625\n",
      "不不，不不不，，，不不，，，不不不，，，不不不，，，不不不，，，不不不，，，不不不，，，不不不，，，\n",
      "6.31096435546875\n",
      "6.189857177734375\n",
      "不不，人不不，，，不不，不不不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人\n",
      "6.325186767578125\n",
      "6.210989990234375\n",
      "不不，人人人，，，人人人，人人人人，人不不人，人人人人，人人不人，人人人人，人人不人，人人人人，人人\n",
      "6.361985473632813\n",
      "6.421025390625\n",
      "不不，不不不，，，不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不\n",
      "6.36652587890625\n",
      "6.178685302734375\n",
      "不不，不不不，，，不不不，不不不，，，不不不，，，不不不，，，不不不，，，不不不，，，不不不，，，不\n",
      "6.239972534179688\n",
      "6.336828002929687\n",
      "不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不\n",
      "6.3615966796875\n",
      "6.399166870117187\n",
      "不不，人不不，，，不不，不不不，不不不，，，不不不，不不不，，，不不不，不不不，，，不不不，不人不，\n",
      "6.329559326171875\n",
      "6.184526977539062\n",
      "不不，人不不，，，不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不不，不不\n",
      "6.181858520507813\n",
      "6.3120751953125\n",
      "不不不，人不不不，不人不不，不不不不，不人不不，不人不不，不人不不，不人不不，不人不不，不人不不，不\n",
      "6.20226806640625\n",
      "6.313201904296875\n",
      "不不不，人不不，，不，不人不，，，不不，不不，不不，不不不，不人不，，，不不不，不人不，，，不不不，\n",
      "6.256604614257813\n",
      "6.312938842773438\n",
      "不不，不不不，，不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，\n",
      "6.18726318359375\n",
      "6.271900634765625\n",
      "不不，不不不，，不，不人不不。不不不不，，，不不不，，，不不不，，，不不不，，，不不不，，，不不不，\n",
      "6.308716430664062\n",
      "6.263370971679688\n",
      "不不，不不不，不不，不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不\n",
      "6.29494873046875\n",
      "6.416919555664062\n",
      "不不，不不不，，不，不不不不。不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，\n",
      "6.333257446289062\n",
      "6.352008666992187\n",
      "不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不\n",
      "6.274173583984375\n",
      "6.3717041015625\n",
      "不不，人人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不，不人不\n",
      "6.33283935546875\n",
      "6.3455029296875\n",
      "不不，不不不，不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不，不不不不\n",
      "6.272677001953125\n",
      "6.234293212890625\n",
      "不不，人人不，不中，中中，不中，中中，不中，中中，不中，中中，不中，中中，不中，中中，不中，中中，不\n",
      "6.217301025390625\n",
      "6.124286499023437\n",
      "不不，人人中，中人中，人人不，中人中，人人人，中人人，中人人，中人人，中人人，中人人，中人人，中人人\n",
      "6.197959594726562\n",
      "6.175585327148437\n",
      "不不，人人人，山人不，山不不不，山人不不，山不不不，山人不不，山不不不，山人不不，山不不不，山人不不\n",
      "6.276347045898437\n",
      "6.285274047851562\n",
      "不不，人人人，山人不不。山不不不人。山不不不人。山不不不人。山不不不人。山不不不人。山不不不人。山不\n",
      "6.254063720703125\n",
      "6.316417846679688\n",
      "不不，人人人，。，不不，人人，，，，不，人人不，。，人人，。，人人，。，人人，。，人人，。，人人，。\n",
      "6.125330810546875\n",
      "6.271065673828125\n",
      "不不不，人人不，。，。，人人，。，人人，。，。，人人，人人。。，，，。不，。，人人，。，。，人人，人\n",
      "6.25523681640625\n",
      "6.278218994140625\n",
      "不不不，山不不不，山山不不。不日不不，。不，不不不，，不，不不不，，不，不不不，山山不不。不日不不，\n",
      "6.153870239257812\n",
      "6.2326953125\n",
      "不不不，山山不不，山山不不，不山不不，山山不不，不山不不，山山不不，不山不不，山山不不，不山不不，山\n",
      "6.297040405273438\n",
      "6.288698120117187\n",
      "不不不，山山不不，不山不，。，山山不。，不，不山不不，不山不，。，山山不。，不，不不不不，不山不不，\n",
      "6.232213745117187\n",
      "6.215410766601562\n",
      "不不，山山山，，，人不，山山山，，，人不不。，人。不不山，，人，不不，，人不。不山山，，人，不不，，\n",
      "6.262092895507813\n",
      "6.2691259765625\n",
      "不不，人人人，，，，人，人人，，，人，不人，，人，人人，，，人，不人，，，人不。，人。不人不人，风人\n",
      "6.241619262695313\n",
      "6.37051025390625\n",
      "不不不，人人不不，人人人，人人人，。，人不，人人不不。不人不不，人人人，。，，，人，。人，人人，，，\n",
      "6.293983154296875\n",
      "6.403958129882812\n",
      "一山山，人人不不，人人人人，人人不不，人人不人，人人不人，人人不人，人人不人，人人不人，人人不人，人\n",
      "6.269855346679687\n",
      "6.28302734375\n",
      "不不不，山不不不，山山不不，山不不不，山山不不，山不不不，山山不不，山不不不，山山不不，山不不不，山\n",
      "6.2675408935546875\n",
      "6.284718627929688\n",
      "不不不，山人不不，山人不不，山日不不，山人不不，山日不不，山人不不，山日不不，山人不不，山日不不，山\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-4e397df81d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0m_assert_no_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         return F.cross_entropy(input, target, self.weight, self.size_average,\n\u001b[0;32m--> 601\u001b[0;31m                                self.ignore_index, self.reduce)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m     \"\"\"\n\u001b[0;32m-> 1140\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_loss = 0.0\n",
    "for i in range(50000):\n",
    "    model.train()\n",
    "    rand_data = random.choice(corpus.data)\n",
    "    inputs = Variable(torch.LongTensor(rand_data[:-1]))\n",
    "    targets = Variable(torch.LongTensor(rand_data[1:]))\n",
    "\n",
    "    \n",
    "    hidden = model.init_hidden()\n",
    "    outputs, hidden = model(inputs, hidden)\n",
    "    loss = criterion(outputs, targets)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    total_loss += loss\n",
    "    if i % config.log_interval == 0 and i > 0:\n",
    "        print(total_loss.data[0] / config.log_interval)\n",
    "        total_loss = 0.0\n",
    "    \n",
    "    if i % 100 == 0 and i > 0:\n",
    "        gen_words = generate2(model, corpus.words)\n",
    "        print(''.join(gen_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
